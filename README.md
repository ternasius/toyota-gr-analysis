# Toyota GR Cup Race Telemetry Analysis

A comprehensive race telemetry analysis system for Toyota GR Cup racing data, featuring data processing scripts and an interactive web dashboard for visualizing and comparing lap performance.

## Project Overview

This project provides tools to analyze race telemetry data from Toyota GR Cup events. It consists of:

1. **Data Processing Pipeline** - Python scripts to clean and optimize raw telemetry data
2. **Interactive Dashboard** - React-based web application for visualizing and comparing lap performance

## Quick Start

### Option 1: Use Online (Recommended)

Access the live dashboard at: **[Your Vercel URL]**

No setup required! Data is hosted on GitHub Pages and loads on-demand.

### Option 2: Run Locally (For Development)

```bash
# Navigate to dashboard
cd dashboard

# Install dependencies
npm install

# Start development server
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) in your browser.

The dashboard will load data from GitHub Pages automatically.

### Option 3: Process Custom Data (Advanced)

Only needed if you want to add new tracks or modify existing data:

1. **Download raw data** from [trddev.com/hackathon-2025](https://trddev.com/hackathon-2025/) into `datasets/`

2. **Install Python dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Clean and format data** (creates `datasets_clean/`):
   ```bash
   jupyter notebook notebooks/data_prep.ipynb
   # Run all cells
   ```

4. **Trim to top 10 laps** (creates `datasets_trimmed/`):
   ```bash
   jupyter notebook notebooks/data_trim.ipynb
   # Run all cells
   ```

5. **Update dashboard to use local data**:
   ```bash
   # Edit dashboard/.env
   VITE_DATA_BASE_URL=/datasets_trimmed
   ```

6. **Run dashboard locally**:
   ```bash
   cd dashboard
   npm run dev
   ```

## Project Structure

```
.
├── datasets/                    # Raw race data (download from TRD)
├── datasets_clean/              # Cleaned data (generated by data_prep.ipynb)
├── datasets_trimmed/            # Top 10 laps only (generated by data_trim.ipynb)
├── lap_exports/                 # Exported laps for upload (generated by extract_single_lap.ipynb)
├── notebooks/                   # Data processing notebooks
│   ├── data_prep.ipynb          # Step 1: Clean and format raw data
│   ├── data_trim.ipynb          # Step 2: Trim to top 10 fastest laps
│   └── extract_single_lap.ipynb # Step 3: Extract a lap for upload
├── scripts/                     # Utility scripts
│   └── README.md
├── dashboard/                   # Web dashboard application
│   ├── src/                     # React application code
│   ├── public/                  # Static assets
│   └── README.md
└── README.md                    # This file
```

## Features

### Data Processing (Optional - For Custom Data)
- **data_prep.ipynb**: Cleans and formats raw race data
- **data_trim.ipynb**: Filters to top 10 fastest laps per track
- **extract_single_lap.ipynb**: Extract a single lap for upload and comparison
- Reduces storage by keeping only relevant telemetry
- Handles data quirks and invalid values

### Dashboard
- **Track Selection** - Choose from available race tracks
- **Lap Comparison** - Select and compare up to 5 laps
- **Telemetry Charts** - View speed, throttle, brake, steering, RPM, and gear
- **Interactive Analysis** - Zoom, pan, and explore data
- **Sector Analysis** - Compare performance by track sectors
- **Data Export** - Export telemetry and statistics to CSV
- **File Upload** - Upload your own lap data for comparison against top 10 drivers

## Data Flow

### For Online Users (Default)
```
GitHub Pages (datasets_trimmed/)
    ↓
Web Dashboard (dashboard/)
    ↓
Interactive Visualization
```

### For Local Development with Custom Data
```
Raw Data (datasets/)
    ↓
data_prep.ipynb → Clean & Format
    ↓
Cleaned Data (datasets_clean/)
    ↓
data_trim.ipynb → Top 10 Laps Only
    ↓
Trimmed Data (datasets_trimmed/)
    ↓
Web Dashboard (dashboard/)
    ↓
Interactive Visualization
```

## Technology Stack

### Data Processing (Optional)
- **Python 3.7+** - Data processing
- **Jupyter Notebooks** - Interactive data cleaning
- **Pandas** - Data manipulation

### Dashboard
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool
- **Plotly.js** - Interactive charts
- **Zustand** - State management
- **Tailwind CSS** - Styling
- **IndexedDB** - Client-side caching

## Development

### Data Processing (Only for Custom Data)

**Step 1: Clean raw data**
```bash
jupyter notebook notebooks/data_prep.ipynb
# Run all cells
# Input: datasets/
# Output: datasets_clean/
```

**Step 2: Trim to top 10 laps**
```bash
jupyter notebook notebooks/data_trim.ipynb
# Run all cells
# Input: datasets_clean/
# Output: datasets_trimmed/
```

### Dashboard Development

```bash
cd dashboard

# Development server
npm run dev

# Type checking
npm run type-check

# Production build
npm run build

# Preview production build
npm run preview
```

See `dashboard/README.md` for detailed documentation.

## Deployment

### Deploy Dashboard to Vercel

1. Push your code to GitHub
2. Go to [vercel.com/new](https://vercel.com/new)
3. Import your repository
4. Click "Deploy"

The dashboard will be live at `https://your-project.vercel.app`

### Host Data on GitHub Pages

1. Create a new public repo for data
2. Upload `datasets_trimmed/` folder
3. Enable GitHub Pages in repo settings
4. Update `dashboard/.env`:
   ```bash
   VITE_DATA_BASE_URL=https://YOUR_USERNAME.github.io/data-repo
   ```
5. Redeploy dashboard to Vercel

Now users load data on-demand from GitHub Pages (free, unlimited bandwidth).

## Uploading Your Own Lap for Analysis

You can upload your own lap data to compare against the top 10 drivers. The dashboard will show detailed delta analysis including sector times, brake usage, and key performance points.

### Step 1: Extract a Lap from Your Data

Use the `extract_single_lap.ipynb` notebook to prepare a lap for upload:

```bash
jupyter notebook notebooks/extract_single_lap.ipynb
```

**Configure the notebook:**
```python
# Set these parameters in the notebook
TRACK_FOLDER = 'cota1'      # Your track folder
DRIVER_NUMBER = 7           # Your driver number
LAP_NUMBER = 5              # Lap to extract
```

**Run all cells** - The notebook will:
1. Load telemetry from your track folder
2. Extract the specified lap
3. Validate all required columns are present
4. Export to `lap_exports/lap_{driver}_{lap}_{track}.csv`

### Step 2: Upload to Dashboard

1. Open the dashboard in your browser
2. Click the **UPLOAD** button in the top navigation
3. Drag and drop your CSV file or click to browse
4. Wait for validation and processing (~1-2 seconds)
5. View your lap comparison!

### Required CSV Format

Your uploaded CSV must include these columns:
- `timestamp` - ISO 8601 format (e.g., "2025-09-05T00:49:11.249Z")
- `speed` - Vehicle speed in km/h
- `Steering_Angle` - Steering angle in degrees
- `pbrake_f` - Front brake pressure in bar
- `pbrake_r` - Rear brake pressure in bar
- `aps` - Throttle position (0-101%)

**Optional but recommended columns:**
- `gear` - Current gear
- `nmot` - Engine RPM
- `accx_can` - Longitudinal acceleration
- `accy_can` - Lateral acceleration

### What You'll See After Upload

The dashboard displays comprehensive analysis:

**Overall Comparison:**
- Total lap time delta vs fastest reference lap
- Your lap time vs reference lap time

**Sector Analysis:**
- Time delta for each sector
- Cumulative time gained/lost

**Key Performance Metrics:**
- Max Speed comparison
- Min Speed comparison (slowest corner)
- Brake Usage percentage (how often you're on the brakes)

**Best/Worst Points:**
- Where you gained the most time
- Where you lost the most time
- Average delta across the lap

**Telemetry Overlay:**
- Your lap appears as a dashed line on all charts
- Compare speed, throttle, brake, steering, RPM, and gear
- Zoom and pan to analyze specific sections

### Tips for Best Results

1. **Use clean data** - Ensure your lap has valid telemetry throughout
2. **Match the track** - Select the same track in the dashboard before uploading
3. **Complete laps only** - Upload full laps from start/finish line to start/finish line
4. **Check file size** - Keep files under 50MB (typical lap is 1-5MB)

### Troubleshooting Upload Issues

**"Missing required columns"**
- Use `extract_single_lap.ipynb` to ensure proper format
- Check that your CSV has all required columns

**"Invalid timestamp format"**
- Timestamps must be ISO 8601 format
- The notebook handles this automatically

**"Throttle position outside valid range"**
- Values must be 0-101% (1% tolerance for sensor noise)
- The notebook validates this automatically

**"Upload failed"**
- Check browser console (F12) for detailed error
- Ensure file is valid CSV format
- Try a different lap or re-export

## Data Format

### Raw Data (datasets/)
Downloaded from TRD, contains all race sessions and laps.

### Cleaned Data (datasets_clean/)
Generated by `data_prep.ipynb`:
- Standardized format
- Fixed data quirks
- Consistent column names

### Trimmed Data (datasets_trimmed/)
Generated by `data_trim.ipynb`:
- `top10_telemetry_per_timestamp.csv` - Telemetry for top 10 laps only
- `top10_lap_times.csv` - Lap times for top 10 laps
- `driver_session_stats.csv` - Driver statistics

This is what the dashboard uses (hosted on GitHub Pages).

### Exported Laps (lap_exports/)
Generated by `extract_single_lap.ipynb`:
- Individual lap CSV files ready for upload
- Validated format with all required columns
- Optimized for dashboard comparison

## Performance

### Data Processing (When Running Locally)
- `data_prep.ipynb`: Cleans all raw race data
- `data_trim.ipynb`: Filters to top 10 laps per track
- Significant size reduction by keeping only fastest laps
- Processing time: ~1-2 minutes per notebook

### Dashboard
- Initial load: ~2 seconds
- Track selection: ~0.5 seconds
- Lap selection: ~1 second
- Supports 6 simultaneous charts
- Handles 2000+ data points per lap

## Requirements

### For Online Use
- Modern web browser (Chrome, Firefox, Safari, Edge)
- Internet connection

### For Local Development
- Node.js 18 or higher
- npm or yarn

### For Custom Data Processing (Optional)
- Python 3.7 or higher
- Jupyter Notebook
- pandas, numpy (see requirements.txt)

### Dashboard
- Node.js 18 or higher
- npm or yarn
- Modern web browser (Chrome, Firefox, Safari, Edge)

## Configuration

### Environment Variables

The dashboard uses a single `.env` file:

```bash
# Data location
VITE_DATA_BASE_URL=/datasets_trimmed

# Performance settings
VITE_MAX_CACHE_SIZE=104857600
VITE_WORKER_POOL_SIZE=4
VITE_MAX_SELECTED_DRIVERS=5
VITE_DOWNSAMPLE_THRESHOLD=2000

# Feature flags
VITE_ENABLE_ANALYTICS=false
VITE_ENABLE_DEBUG=false
```

## Troubleshooting

### Data Processing Issues (Local Only)

**Problem**: Jupyter notebook can't find data
- Ensure raw data is in `datasets/` folder
- Check that you downloaded data from TRD website

**Problem**: Notebook fails during processing
- Check Python dependencies: `pip install -r requirements.txt`
- Ensure you have pandas and numpy installed

### Dashboard Issues

**Problem**: Charts not showing data
- Check browser console (F12) for errors
- Verify `datasets_trimmed/` folder exists
- Ensure data was processed correctly

**Problem**: Build fails
```bash
# Clear cache and rebuild
rm -rf node_modules dist
npm install
npm run build
```

## License

This project is for race telemetry analysis and educational purposes.

## Support

- **Data Processing**: Open `notebooks/data_prep.ipynb` or `notebooks/data_trim.ipynb`
- **Dashboard**: See `dashboard/README.md`
- **Deployment**: Follow instructions in this README

## Acknowledgments

- Toyota Racing Development (TRD) for providing the race data
- Toyota GR Cup racing series
- Open source community for the tools and libraries used
